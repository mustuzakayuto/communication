{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mustuzakayuto/communication/blob/communication/googleclab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "kjX_Dq0TWoi7"
      },
      "outputs": [],
      "source": [
        "#@title やり方\n",
        "#@markdown ### プログラム起動設定\n",
        "#@markdown ### ngrokサイトで設定\n",
        "#@markdown ##### ngrok サイト <br>https://ngrok.com/\n",
        "#@markdown ##### access token取得 <br> https://www.mgo-tec.com/blog-entry-ngrok-install.html\n",
        "#@markdown ##### domain取得<br> https://qiita.com/youtoy/items/8a79d6954bb37f935f1b\n",
        "\n",
        "#@markdown # access\n",
        "#@markdown ### まずは、ngrok のダッシュボードにログインします。\n",
        "#@markdown ### そして、左のメニューから「Getting Started > Your Authtoken」を選びます。\n",
        "#@markdown ### Copy ボタンをクリックでtokenをコピー\n",
        "\n",
        "\n",
        "#@markdown # hostname(ホストネーム)\n",
        "#@markdown ### まずは、ngrok のダッシュボードにログインします。\n",
        "#@markdown ### そして、左のメニューから「Cloud Edge > Domains」を選びます。\n",
        "#@markdown ### そうすると、上に示した画面が出てくるので「Create Domain」を選びます。\n",
        "#@markdown ### Domainの部分がHostnameに入れる値\n",
        "\n",
        "# 起動するポート設定\n",
        "port = 5000 #@param {type:\"integer\"}\n",
        "# ngrokのtokenを設定\n",
        "access_token=\"\" #@param {type:\"string\"}\n",
        "# ngorkのホストネーム設定\n",
        "hostname=\"\" #@param {type:\"string\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xEY-mlGWWPrb"
      },
      "outputs": [],
      "source": [
        "#@title フォルダー移動とクローン\n",
        "\n",
        "\n",
        "is_git_clone=True  #@param {type:\"boolean\"}\n",
        "if(is_git_clone):\n",
        "  !git clone https://github.com/mustuzakayuto/communication.git\n",
        "  %cd communication\n",
        "!git pull\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNF-cL5kWUoM",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title インストール\n",
        "!apt-get install python3-venv\n",
        "!python3 -m venv virtual_environment/ITalk_ve && source virtual_environment/ITalk_ve/bin/activate && pip install -r requirements.txt\n",
        "!source virtual_environment/ITalk_ve/bin/activate && pip install torch==2.0.0+cu118 torchvision==0.15.0+cu118 torchaudio==2.0.0+cu118 --index-url https://download.pytorch.org/whl/cu118"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "RAv5k9MUjn7g"
      },
      "outputs": [],
      "source": [
        "#@title バグ対策\n",
        "h11_text_data=\"\"\"\n",
        "import re\n",
        "from typing import AnyStr, cast, List, overload, Sequence, Tuple, TYPE_CHECKING, Union\n",
        "\n",
        "from ._abnf import field_name, field_value\n",
        "from ._util import bytesify, LocalProtocolError, validate\n",
        "\n",
        "if TYPE_CHECKING:\n",
        "    from ._events import Request\n",
        "\n",
        "try:\n",
        "    from typing import Literal\n",
        "except ImportError:\n",
        "    from typing_extensions import Literal  # type: ignore\n",
        "\n",
        "\n",
        "# Facts\n",
        "# -----\n",
        "#\n",
        "# Headers are:\n",
        "#   keys: case-insensitive ascii\n",
        "#   values: mixture of ascii and raw bytes\n",
        "#\n",
        "# \"Historically, HTTP has allowed field content with text in the ISO-8859-1\n",
        "# charset [ISO-8859-1], supporting other charsets only through use of\n",
        "# [RFC2047] encoding.  In practice, most HTTP header field values use only a\n",
        "# subset of the US-ASCII charset [USASCII]. Newly defined header fields SHOULD\n",
        "# limit their field values to US-ASCII octets.  A recipient SHOULD treat other\n",
        "# octets in field content (obs-text) as opaque data.\"\n",
        "# And it deprecates all non-ascii values\n",
        "#\n",
        "# Leading/trailing whitespace in header names is forbidden\n",
        "#\n",
        "# Values get leading/trailing whitespace stripped\n",
        "#\n",
        "# Content-Disposition actually needs to contain unicode semantically; to\n",
        "# accomplish this it has a terrifically weird way of encoding the filename\n",
        "# itself as ascii (and even this still has lots of cross-browser\n",
        "# incompatibilities)\n",
        "#\n",
        "# Order is important:\n",
        "# \"a proxy MUST NOT change the order of these field values when forwarding a\n",
        "# message\"\n",
        "# (and there are several headers where the order indicates a preference)\n",
        "#\n",
        "# Multiple occurences of the same header:\n",
        "# \"A sender MUST NOT generate multiple header fields with the same field name\n",
        "# in a message unless either the entire field value for that header field is\n",
        "# defined as a comma-separated list [or the header is Set-Cookie which gets a\n",
        "# special exception]\" - RFC 7230. (cookies are in RFC 6265)\n",
        "#\n",
        "# So every header aside from Set-Cookie can be merged by b\", \".join if it\n",
        "# occurs repeatedly. But, of course, they can't necessarily be split by\n",
        "# .split(b\",\"), because quoting.\n",
        "#\n",
        "# Given all this mess (case insensitive, duplicates allowed, order is\n",
        "# important, ...), there doesn't appear to be any standard way to handle\n",
        "# headers in Python -- they're almost like dicts, but... actually just\n",
        "# aren't. For now we punt and just use a super simple representation: headers\n",
        "# are a list of pairs\n",
        "#\n",
        "#   [(name1, value1), (name2, value2), ...]\n",
        "#\n",
        "# where all entries are bytestrings, names are lowercase and have no\n",
        "# leading/trailing whitespace, and values are bytestrings with no\n",
        "# leading/trailing whitespace. Searching and updating are done via naive O(n)\n",
        "# methods.\n",
        "#\n",
        "# Maybe a dict-of-lists would be better?\n",
        "\n",
        "_content_length_re = re.compile(rb\"[0-9]+\")\n",
        "_field_name_re = re.compile(field_name.encode(\"ascii\"))\n",
        "_field_value_re = re.compile(field_value.encode(\"ascii\"))\n",
        "\n",
        "\n",
        "class Headers(Sequence[Tuple[bytes, bytes]]):\n",
        "    __slots__ = \"_full_items\"\n",
        "\n",
        "    def __init__(self, full_items: List[Tuple[bytes, bytes, bytes]]) -> None:\n",
        "        self._full_items = full_items\n",
        "\n",
        "    def __bool__(self) -> bool:\n",
        "        return bool(self._full_items)\n",
        "\n",
        "    def __eq__(self, other: object) -> bool:\n",
        "        return list(self) == list(other)  # type: ignore\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self._full_items)\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return \"<Headers(%s)>\" % repr(list(self))\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Tuple[bytes, bytes]:  # type: ignore[override]\n",
        "        _, name, value = self._full_items[idx]\n",
        "        return (name, value)\n",
        "\n",
        "    def raw_items(self) -> List[Tuple[bytes, bytes]]:\n",
        "        return [(raw_name, value) for raw_name, _, value in self._full_items]\n",
        "\n",
        "\n",
        "HeaderTypes = Union[\n",
        "    List[Tuple[bytes, bytes]],\n",
        "    List[Tuple[bytes, str]],\n",
        "    List[Tuple[str, bytes]],\n",
        "    List[Tuple[str, str]],\n",
        "]\n",
        "\n",
        "\n",
        "@overload\n",
        "def normalize_and_validate(headers: Headers, _parsed: Literal[True]) -> Headers:\n",
        "    ...\n",
        "\n",
        "\n",
        "@overload\n",
        "def normalize_and_validate(headers: HeaderTypes, _parsed: Literal[False]) -> Headers:\n",
        "    ...\n",
        "\n",
        "\n",
        "@overload\n",
        "def normalize_and_validate(\n",
        "    headers: Union[Headers, HeaderTypes], _parsed: bool = False\n",
        ") -> Headers:\n",
        "    ...\n",
        "\n",
        "\n",
        "def normalize_and_validate(\n",
        "    headers: Union[Headers, HeaderTypes], _parsed: bool = False\n",
        ") -> Headers:\n",
        "    new_headers = []\n",
        "    seen_content_length = None\n",
        "    saw_transfer_encoding = False\n",
        "    for name, value in headers:\n",
        "        # For headers coming out of the parser, we can safely skip some steps,\n",
        "        # because it always returns bytes and has already run these regexes\n",
        "        # over the data:\n",
        "        if not _parsed:\n",
        "            name = bytesify(name)\n",
        "            value = bytesify(value)\n",
        "            validate(_field_name_re, name, \"Illegal header name {!r}\", name)\n",
        "            validate(_field_value_re, value, \"Illegal header value {!r}\", value)\n",
        "        assert isinstance(name, bytes)\n",
        "        assert isinstance(value, bytes)\n",
        "\n",
        "        raw_name = name\n",
        "        name = name.lower()\n",
        "        if name == b\"content-length\":\n",
        "            lengths = {length.strip() for length in value.split(b\",\")}\n",
        "            if len(lengths) != 1:\n",
        "                raise LocalProtocolError(\"conflicting Content-Length headers\")\n",
        "            value = lengths.pop()\n",
        "            validate(_content_length_re, value, \"bad Content-Length\")\n",
        "            if seen_content_length is None:\n",
        "                seen_content_length = value\n",
        "                new_headers.append((raw_name, name, value))\n",
        "            elif seen_content_length != value:\n",
        "                raise LocalProtocolError(\"conflicting Content-Length headers\")\n",
        "        elif name == b\"transfer-encoding\":\n",
        "            # \"A server that receives a request message with a transfer coding\n",
        "            # it does not understand SHOULD respond with 501 (Not\n",
        "            # Implemented).\"\n",
        "            # https://tools.ietf.org/html/rfc7230#section-3.3.1\n",
        "            if saw_transfer_encoding:\n",
        "                raise LocalProtocolError(\n",
        "                    \"multiple Transfer-Encoding headers\", error_status_hint=501\n",
        "                )\n",
        "            # \"All transfer-coding names are case-insensitive\"\n",
        "            # -- https://tools.ietf.org/html/rfc7230#section-4\n",
        "            value = value.lower()\n",
        "            if value != b\"chunked\":\n",
        "                raise LocalProtocolError(\n",
        "                    \"Only Transfer-Encoding: chunked is supported\",\n",
        "                    error_status_hint=501,\n",
        "                )\n",
        "            saw_transfer_encoding = True\n",
        "            new_headers.append((raw_name, name, value))\n",
        "        else:\n",
        "            new_headers.append((raw_name, name, value))\n",
        "    return Headers(new_headers)\n",
        "\n",
        "\n",
        "def get_comma_header(headers: Headers, name: bytes) -> List[bytes]:\n",
        "    # Should only be used for headers whose value is a list of\n",
        "    # comma-separated, case-insensitive values.\n",
        "    #\n",
        "    # The header name `name` is expected to be lower-case bytes.\n",
        "    #\n",
        "    # Connection: meets these criteria (including cast insensitivity).\n",
        "    #\n",
        "    # Content-Length: technically is just a single value (1*DIGIT), but the\n",
        "    # standard makes reference to implementations that do multiple values, and\n",
        "    # using this doesn't hurt. Ditto, case insensitivity doesn't things either\n",
        "    # way.\n",
        "    #\n",
        "    # Transfer-Encoding: is more complex (allows for quoted strings), so\n",
        "    # splitting on , is actually wrong. For example, this is legal:\n",
        "    #\n",
        "    #    Transfer-Encoding: foo; options=\"1,2\", chunked\n",
        "    #\n",
        "    # and should be parsed as\n",
        "    #\n",
        "    #    foo; options=\"1,2\"\n",
        "    #    chunked\n",
        "    #\n",
        "    # but this naive function will parse it as\n",
        "    #\n",
        "    #    foo; options=\"1\n",
        "    #    2\"\n",
        "    #    chunked\n",
        "    #\n",
        "    # However, this is okay because the only thing we are going to do with\n",
        "    # any Transfer-Encoding is reject ones that aren't just \"chunked\", so\n",
        "    # both of these will be treated the same anyway.\n",
        "    #\n",
        "    # Expect: the only legal value is the literal string\n",
        "    # \"100-continue\". Splitting on commas is harmless. Case insensitive.\n",
        "    #\n",
        "    out: List[bytes] = []\n",
        "    for _, found_name, found_raw_value in headers._full_items:\n",
        "        if found_name == name:\n",
        "            found_raw_value = found_raw_value.lower()\n",
        "            for found_split_value in found_raw_value.split(b\",\"):\n",
        "                found_split_value = found_split_value.strip()\n",
        "                if found_split_value:\n",
        "                    out.append(found_split_value)\n",
        "    return out\n",
        "\n",
        "\n",
        "def set_comma_header(headers: Headers, name: bytes, new_values: List[bytes]) -> Headers:\n",
        "    # The header name `name` is expected to be lower-case bytes.\n",
        "    #\n",
        "    # Note that when we store the header we use title casing for the header\n",
        "    # names, in order to match the conventional HTTP header style.\n",
        "    #\n",
        "    # Simply calling `.title()` is a blunt approach, but it's correct\n",
        "    # here given the cases where we're using `set_comma_header`...\n",
        "    #\n",
        "    # Connection, Content-Length, Transfer-Encoding.\n",
        "    new_headers: List[Tuple[bytes, bytes]] = []\n",
        "    for found_raw_name, found_name, found_raw_value in headers._full_items:\n",
        "        if found_name != name:\n",
        "            new_headers.append((found_raw_name, found_raw_value))\n",
        "    for new_value in new_values:\n",
        "        new_headers.append((name.title(), new_value))\n",
        "    return normalize_and_validate(new_headers)\n",
        "\n",
        "\n",
        "def has_expect_100_continue(request: \"Request\") -> bool:\n",
        "    # https://tools.ietf.org/html/rfc7231#section-5.1.1\n",
        "    # \"A server that receives a 100-continue expectation in an HTTP/1.0 request\n",
        "    # MUST ignore that expectation.\"\n",
        "    if request.http_version < b\"1.1\":\n",
        "        return False\n",
        "    expect = get_comma_header(request.headers, b\"expect\")\n",
        "    return b\"100-continue\" in expect\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "with open(\"virtual_environment/ITalk_ve/lib/python3.10/site-packages/h11/_headers.py\",\"w\")as f:\n",
        "  f.write(h11_text_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9GY-x0qyWW27"
      },
      "outputs": [],
      "source": [
        "#@title データベース初期化\n",
        "is_create_date_base=True#@param {type:\"boolean\"}\n",
        "if(is_create_date_base):\n",
        "  !python3 create_data_base.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "wzzp_wbYWZE8"
      },
      "outputs": [],
      "source": [
        "#@title プログラム起動\n",
        "\n",
        "!source virtual_environment/ITalk_ve/bin/activate && python3 app_modal.py $port  $access_token $hostname\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPI4nmqDKH4QRSTHx7bjGkl",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}